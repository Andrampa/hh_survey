{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dressed-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import arcpy,openpyxl\n",
    "from pandas import ExcelWriter\n",
    "from datetime import datetime\n",
    "import os\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import SpatialDataFrame\n",
    "from shutil import copyfile\n",
    "from openpyxl.utils.cell import get_column_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "amber-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importallsheets(in_excel, out_gdb):\n",
    "    ###this function import all sheets of an xlsx file into separate tables inside a GDB (with same name)\n",
    "    print(\"max_counter: %s\" % max_counter)\n",
    "    counter = 0\n",
    "    workbook = xlrd.open_workbook(in_excel)\n",
    "    sheets = [sheet.name for sheet in workbook.sheets()]\n",
    "\n",
    "    print('{} sheets found: {}'.format(len(sheets), ','.join(sheets)))\n",
    "    for sheet in sheets:\n",
    "        counter +=1\n",
    "        if counter <= max_counter:\n",
    "            # The out_table is based on the input excel file name\n",
    "            # a underscore (_) separator followed by the sheet name\n",
    "            out_table = os.path.join(\n",
    "                out_gdb,\n",
    "                arcpy.ValidateTableName(\n",
    "                    \"{0}\".format(sheet),\n",
    "                    out_gdb))\n",
    "\n",
    "            print('Converting {} to {}'.format(sheet, out_table))\n",
    "\n",
    "            # Perform the conversion\n",
    "            arcpy.ExcelToTable_conversion(in_excel, out_table, sheet)\n",
    "            \n",
    "\n",
    "def make_attribute_dict(fc, code_field, value_field):\n",
    "    #this function creates a dictionary based on a GDB table\n",
    "    attdict = {}\n",
    "    with arcpy.da.SearchCursor(fc, [code_field, value_field]) as cursor:\n",
    "        for row in cursor:\n",
    "            attdict[row[0]] = row[1]\n",
    "    return attdict\n",
    "\n",
    "def fix_category_formatting(category):\n",
    "    #this function improves and standardizes the formatting of the categories' descriptions\n",
    "     return category.replace(\"[\",\"(\").replace(\"]\",\")\").replace(\"(specify)\",\"\").replace(\"/ \",\", \").capitalize().replace(\"adps\",\"ADPs\").replace(\"idp\",\"IDP\").replace(\"covid\",\"COVID\").replace(\" , \",\", \").replace(\"staplec\",\"staple\") \n",
    "\n",
    "def count_number_of_questions_qname(questionnaire_file):\n",
    "    questionnaire_df = pd.read_excel(pd.ExcelFile(questionnaire_file), sheet_name='survey',skiprows=2)\n",
    "    questionnaire_df = questionnaire_df[['Q Name']]\n",
    "    list_questions = questionnaire_df.dropna().values.tolist()\n",
    "    list_questions = [item for sublist in list_questions for item in sublist]\n",
    "    n_of_questions = len(list_questions)\n",
    "    return list_questions, n_of_questions\n",
    "\n",
    "def count_number_of_questions_sqname(questionnaire_file):\n",
    "    questionnaire_df = pd.read_excel(pd.ExcelFile(questionnaire_file), sheet_name='survey',skiprows=2)\n",
    "    questionnaire_df = questionnaire_df[['Suggested Qname']]\n",
    "    list_questions = questionnaire_df.dropna().values.tolist()\n",
    "    list_questions = [item for sublist in list_questions for item in sublist]\n",
    "    n_of_questions = len(list_questions)\n",
    "    return list_questions, n_of_questions\n",
    "    \n",
    "\n",
    "def read_questionnaire(input_questionnaire_file, writer):\n",
    "    ##this section of the script reads the survey excel file and creates an excel file with multiple sheets:\n",
    "    ### each sheet contains the coded value and description for a \"Single choice\" or \"Open Ended-Select All That Apply\" question.\n",
    "    ###moreover, it creates and populates several lists that will be used later for defining each field of the final table names, types and domains\n",
    "\n",
    "    #print(\"Opening questionnaire DF\")\n",
    "    quest_df = pd.read_excel(open(input_questionnaire_file, 'rb'), sheet_name='survey',skiprows=2)\n",
    "    #create a list of all possible numbering\n",
    "    numbering = [\"%s)\" % n for n in range(1,200)] ## 1), 2), ... 200)\n",
    "    # initialize list of lists that will store the results\n",
    "    dict_derived_fieldnames = {} #this dict will group all derived fields in case of \"Select All That Apply\" type of questions\n",
    "    field_names_list = [] ##this list will contain all fields of the final table\n",
    "    text_type_fields = [] ##this list will contain all fields of the final table with TEXT type\n",
    "    range_type_fields = [] ##this list will contain all fields of the final table storing RANGE data  (will be LONG type)\n",
    "    double_type_fields = [] ##this list will contain all fields of the final table storing DOUBLE data  \n",
    "    ##iterate the following for each row (so each question of the questionnaire)\n",
    "    all_derived_fieldnames = []\n",
    "    all_answers_with_other_option = [] ##this list will contain all \"Other: specify\" fields\n",
    "    quest_df = quest_df[quest_df['Suggested Qname'].notna()]\n",
    "    for index, row in quest_df.iterrows():\n",
    "        question_name = []\n",
    "        question_type = []\n",
    "        try:\n",
    "            first_derived_fieldname = \"\" #the name of the first derived field will be the main of the domain table\n",
    "            derived_fieldnames = []\n",
    "            codes_and_labels = []\n",
    "            categories = str(row['English']).replace(\"\\t\",\"\")\n",
    "            question_name = row['Suggested Qname'].strip()  #Q Name\n",
    "            question_type = row['Q Type']\n",
    "            programming_instructions = row['Programming Instructions'] #this field contains coded values for crop_main\n",
    "            #print(\"\\n\\n----%s----\" % question_name)\n",
    "            #only for questions with pre-defined categories need domains\n",
    "            if question_type in (\"StartRecording\",\"Single Choice\",\"Open Ended-Single Choice\", \"Open Ended - Single Choice\", \"Open Ended-Select All That Apply\",\n",
    "                                 \"Select All That Apply\",\"Open Ended - Select All That Apply \"):\n",
    "                if question_name == 'crp_main': #for this question only, coded values should be taken from field programming_instructions\n",
    "                    programming_lines = programming_instructions.splitlines()\n",
    "                    for programming_line in programming_lines:\n",
    "                        if \")\" in programming_line:\n",
    "                            #print(programming_line)\n",
    "                            index, category = programming_line.split(\")\")\n",
    "                            category = fix_category_formatting(category)\n",
    "                            codes_and_labels.append([index, category])\n",
    "                else:\n",
    "                    #find all numbering present in the category string\n",
    "                    numbering_in_text = [n for n in numbering if n in categories]\n",
    "                    #print(numbering_in_text)\n",
    "                    ##the following loop creates a list \"codes_and_labels\" with all available codes&labels for each question\n",
    "                    for index in range(0,len(numbering_in_text)):\n",
    "                        start = categories.find(numbering_in_text[index]) + len(numbering_in_text[index])\n",
    "                        try:\n",
    "                            end = categories.find(numbering_in_text[index + 1])\n",
    "                            substring = categories[start:end].strip()\n",
    "                        except:\n",
    "                            # it fails during the last loop -> the last option is usually at the end of the string\n",
    "                            substring = categories[start:].strip()\n",
    "                        #print(substring)\n",
    "                        category = fix_category_formatting(substring)\n",
    "                        codes_and_labels.append([index +1, category])\n",
    "\n",
    "                if question_type not in [\"Open Ended-Select All That Apply\",\"Select All That Apply\",\"Open Ended - Select All That Apply \"]:\n",
    "                    #so questions with NO derived fields\n",
    "                    field_names_list.append(question_name.strip())\n",
    "                    codes_and_labels_df = pd.DataFrame(codes_and_labels, columns=['code', 'label'])\n",
    "                    codes_and_labels_df.to_excel(writer, sheet_name=question_name)\n",
    "                else:\n",
    "                    #so questions with derived fields\n",
    "                    numbering_in_qname = [n for n in numbering if n in question_name]\n",
    "                    for index in range(0, len(numbering_in_qname)):\n",
    "                        start = question_name.find(numbering_in_qname[index]) + len(numbering_in_qname[index])\n",
    "                        try:\n",
    "                            end = question_name.find(numbering_in_qname[index + 1])\n",
    "                            derived_field_name = question_name[start:end].strip()\n",
    "                        except:\n",
    "                            # it fails during the last loop -> the last option is usually at the end of the string\n",
    "                            derived_field_name = question_name[start:].strip()\n",
    "                        all_derived_fieldnames.append(derived_field_name)\n",
    "                        derived_fieldnames.append(derived_field_name)\n",
    "                        field_names_list.append(derived_field_name)\n",
    "                        if derived_field_name[-6:] == \"_other\": ##this field will need to be STRING - with no domain (since it's a 'other specify')\n",
    "                            all_answers_with_other_option.append(derived_field_name)\n",
    "                        if index == 0:\n",
    "                            first_derived_fieldname = derived_field_name\n",
    "                            codes_and_labels_df = pd.DataFrame(codes_and_labels, columns=['code', 'label'])\n",
    "                            #codes_and_labels_df.to_excel(writer, sheet_name=derived_field_name) #we don't need domain table for derived fields, since they will use YES NOT domain table\n",
    "                    dict_derived_fieldnames[first_derived_fieldname] = all_derived_fieldnames\n",
    "            elif question_type == \"Range\":\n",
    "                #these questions will be associated to LONG type fields\n",
    "                field_names_list.append(question_name.strip())\n",
    "                range_type_fields.append(question_name)\n",
    "            elif question_type == \"Open Ended\":\n",
    "                #these questions will be associated to TEXT type fields\n",
    "                if not pd.isnull(question_name): #NaN rows we want to skip (i.e. OptIn question without a name in the survey)\n",
    "                    field_names_list.append(question_name)\n",
    "                    text_type_fields.append(question_name)\n",
    "            else:\n",
    "                #print(\"QUESTION SKIPPED ---------\", question_name, question_type)\n",
    "                pass\n",
    "        except Exception as e: \n",
    "            print(\"Failed question %s (type: %s) for error: %s \" % (question_name, question_type,e))\n",
    "\n",
    "    #adding Yes No table (for derived fields domain)\n",
    "    d = {1:\"Yes\",0:\"No\"}\n",
    "    yesno_df = pd.DataFrame(d.items(), columns=['code', 'label'])\n",
    "    yesno_df.to_excel(writer, sheet_name='yes_no')\n",
    "    #print(\"Saving codes and labels %s\" % coded_values_file)\n",
    "\n",
    "    #print(all_answers_with_other_option)\n",
    "\n",
    "    #creating additional sheet with all derived fields, that will be used for a script that ensures that also these values are within the domains in the output table, in a later stage\n",
    "    list_of_yes_no_fields = []\n",
    "    for derived_field in all_derived_fieldnames:\n",
    "        if derived_field not in all_answers_with_other_option:\n",
    "            list_of_yes_no_fields.append(derived_field)\n",
    "\n",
    "    derived_fields_df = pd.DataFrame(list_of_yes_no_fields) \n",
    "    derived_fields_df.to_excel(writer, sheet_name='derived_fields') \n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    writer.save()\n",
    "    \n",
    "def detect_enumerator(geopoll_or_kobo_template):\n",
    "    enumerator = \"\"\n",
    "    if \"kobo\" in geopoll_or_kobo_template.lower():\n",
    "        country_df.columns = country_df.columns.str.replace(\"[/]\", \"\")\n",
    "        enumerator = \"kobo\"\n",
    "    elif \"geopoll\" in geopoll_or_kobo_template.lower():\n",
    "        enumerator = \"geopoll\"\n",
    "    else:\n",
    "        print(\"Please include Geopoll or Kobo inside the filename: %s \" % geopoll_or_kobo_template)\n",
    "        enumerator = \"Please include Geopoll or Kobo inside the filename\"\n",
    "    return enumerator\n",
    "\n",
    "def insert_sheet_with_adm2_reference(questionnaire_file,adm0_iso3):\n",
    "    gis = GIS(\"https://hqfao.maps.arcgis.com\")\n",
    "    item = gis.content.get('3596c3ad318849068eda21517ade30be')\n",
    "    flayer = item.layers[0]\n",
    "    #queryies content of interest\n",
    "    query = \"adm0_ISO3 = '\" + adm0_iso3 +\"'\"\n",
    "    sdf = flayer.query(where=query).sdf\n",
    "    #print(sdf.head())\n",
    "    del sdf['OBJECTID']\n",
    "    del sdf['validity']\n",
    "    del sdf['Shape__Area']\n",
    "    del sdf['Shape__Length']\n",
    "    del sdf['SHAPE']\n",
    "    #print(sdf.head())\n",
    "    excel_book = openpyxl.load_workbook(questionnaire_file)\n",
    "    with pd.ExcelWriter(questionnaire_file, engine='openpyxl') as writer:\n",
    "        writer.book = excel_book\n",
    "        sdf.to_excel(writer, 'ADMIN info', index=False)\n",
    "        writer.save()\n",
    "        \n",
    "    return sdf\n",
    "\n",
    "def find_and_replace_strings_in_df(questionnaire_file):\n",
    "    replacing_table_df = pd.read_excel(pd.ExcelFile(questionnaire_file), 'Additional information', skiprows=1)\n",
    "    replacing_table_df = replacing_table_df[['Original','Replacement']]\n",
    "\n",
    "    workbook = openpyxl.load_workbook(questionnaire_file)\n",
    "    workbook.sheetnames\n",
    "    worksheet = workbook[\"survey\"]\n",
    "\n",
    "    number_of_rows = worksheet.max_row #Number of Rows\n",
    "    number_of_columns = worksheet.max_column #Number of Columns\n",
    "\n",
    "    replacementTextKeyPairs = {'$ADMIN1$': replacing_table_df.iloc[0]['Replacement'],\n",
    "                               '$ADMIN2$': replacing_table_df.iloc[1]['Replacement'],\n",
    "                               '$currency$': replacing_table_df.iloc[2]['Replacement'],\n",
    "                               '$MIN SALARY$': replacing_table_df.iloc[3]['Replacement'],\n",
    "                               '$MAX SALARY$': replacing_table_df.iloc[4]['Replacement'],\n",
    "                               '$THRESHOLD$': replacing_table_df.iloc[5]['Replacement'],\n",
    "                               '$season$': replacing_table_df.iloc[6]['Replacement'],\n",
    "                               '$expected or nothing$': replacing_table_df.iloc[7]['Replacement']}\n",
    "    # Iterate over the columns and rows, search\n",
    "    # for the text and replace\n",
    "    for i in range(number_of_columns):\n",
    "        for k in range(number_of_rows):\n",
    "          \n",
    "            cellValue = str(worksheet[get_column_letter(i+1)+str(k+1)].value)\n",
    "            #print(cellValue)\n",
    "            \n",
    "            for key in replacementTextKeyPairs.keys():\n",
    "              \n",
    "                if key in str(cellValue) and str(cellValue) != None:\n",
    "                    newCellValue = cellValue.replace(key,replacementTextKeyPairs.get(key))\n",
    "                    #newCellValue = replacementTextKeyPairs.get(key)\n",
    "                    worksheet[get_column_letter(i+1)+str(k+1)] = str(newCellValue) \n",
    "    workbook.save(questionnaire_file)\n",
    "    \n",
    "def sort_crop_list_by_selection(questionnaire_file):\n",
    "    crop_list_df = pd.read_excel(pd.ExcelFile(questionnaire_file), 'Crop list', skiprows=2)\n",
    "    crop_list_df = crop_list_df[['Select top 10 crops ','GeoPoll code','Dataset code','Label']]\n",
    "    q_name = \"crp_main\"\n",
    "    q_label = \"What has been the main crop that your household has grown for food and income generation in $season$, if any? \\n [OPERATOR: SINGLE RESPONSE. \\\"NO CROP PRODUCTION\\\" IS IN LAST OPTIONS AT THE END.] \\n \\n\"\n",
    "    \n",
    "    workbook = openpyxl.load_workbook(questionnaire_file)\n",
    "    workbook.sheetnames\n",
    "    worksheet = workbook[\"survey\"]\n",
    "    \n",
    "    number_of_rows = worksheet.max_row #Number of Rows\n",
    "    number_of_columns = worksheet.max_column #Number of Columns\n",
    "    \n",
    "\n",
    "\n",
    "    list_choices = crop_list_df['Select top 10 crops '].dropna().values.tolist()\n",
    "    n_of_choices = len(list_choices)\n",
    "\n",
    "\n",
    "    \n",
    "    sorted_crop_list_df = crop_list_df.sort_values(by = ['Select top 10 crops ','GeoPoll code'])\n",
    "    #print(sorted_crop_list_df)\n",
    "    \n",
    "    sorted_crop_list_df['combined'] = sorted_crop_list_df['GeoPoll code'].astype(str)+')'+sorted_crop_list_df['Label']\n",
    "    sorted_crop_list = sorted_crop_list_df[['combined']].values.tolist()\n",
    "    #print(sorted_crop_list)\n",
    "    final_sorted_crop_list = '\\n'.join(map(str, [i[0] for i in sorted_crop_list]))\n",
    "\n",
    "    #print(final_sorted_crop_list)\n",
    "    #print(crop_list_df)\n",
    "\n",
    "    # Iterate over the columns and rows, search\n",
    "    # for the text and replace\n",
    "\n",
    "    for k in range(number_of_rows):\n",
    "          \n",
    "        questionValue = str(worksheet[get_column_letter(2)+str(k+1)].value)\n",
    "        labelValue = str(worksheet[get_column_letter(4)+str(k+1)].value)\n",
    "            #print(cellValue)\n",
    "              \n",
    "        if q_name in str(questionValue) and str(questionValue) != None:\n",
    "              newLabelValue = q_label + final_sorted_crop_list\n",
    "              #newCellValue = replacementTextKeyPairs.get(key)\n",
    "              worksheet[get_column_letter(4)+str(k+1)] = str(newLabelValue) \n",
    "    workbook.save(questionnaire_file)\n",
    "    return n_of_choices\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "needed-hello",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading TEMPLATE questionnaire and creating recap excel file\n",
      "Reading COUNTRY questionnaire and creating recap excel file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###USER DEFINED INPUTS BEGINNING\n",
    "iso3 = \"PHL\"\n",
    "country_questionnaire_file = r'C:\\temp\\household_questionnaire_geopoll_20210525_PH.xlsx' #the questionnaire file that we use for creating the table\n",
    "template_questionnaire_file = r'C:\\git\\hh_survey\\household_questionnaire_geopoll_202105.xlsx' #the questionnaire file that we use for creating the table\n",
    "output_locations = r'C:\\temp\\data_processing_exports'\n",
    "###USER DEFINED INPUTS END\n",
    "\n",
    "execution_messages = ''\n",
    "\n",
    "enumerator = detect_enumerator(country_questionnaire_file)\n",
    "\n",
    "print(\"Reading TEMPLATE questionnaire and creating recap excel file\")\n",
    "questionnaire_file = template_questionnaire_file\n",
    "temp_path = output_locations\n",
    "\n",
    "startTime = datetime.now()\n",
    "now = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "coded_values_file = os.path.join(temp_path, \"coded_values_%s_template.xlsx\" % now) #intermediary output file with all categories and codes extracted from the questionnaire\n",
    "writer = pd.ExcelWriter(coded_values_file, engine='xlsxwriter')\n",
    "field_names_list = []\n",
    "max_counter = 3000 #for testing purposes, we may need to limit the execution only to some items\n",
    "read_questionnaire(questionnaire_file, writer)\n",
    "\n",
    "print(\"Reading COUNTRY questionnaire and creating recap excel file\")\n",
    "country_coded_values_file = os.path.join(temp_path, \"coded_values_%s_country.xlsx\" % now) #intermediary output file with all categories and codes extracted from the questionnaire\n",
    "country_writer = pd.ExcelWriter(country_coded_values_file, engine='xlsxwriter')\n",
    "field_names_list = []\n",
    "max_counter = 3000 #for testing purposes, we may need to limit the execution only to some items\n",
    "read_questionnaire(country_questionnaire_file, country_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "matched-opportunity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNTING NUMBER OF QUESTIONS\n",
      "QName Field - Number of questions in the Template Questionnaire: 126\n",
      "QName Field - Number of questions in the Country Questionnaire: 129\n",
      "\n",
      "SuggestedQName Field - Number of questions in the Template Questionnaire: 124\n",
      "SuggestedQName Field - Number of questions in the Country Questionnaire: 124\n"
     ]
    }
   ],
   "source": [
    "print (\"COUNTING NUMBER OF QUESTIONS\")\n",
    "\n",
    "T_sqname_list_questions, T_sqname_n_of_questions = count_number_of_questions_sqname(questionnaire_file)\n",
    "T_qname_list_questions, T_qname_n_of_questions = count_number_of_questions_qname(questionnaire_file)\n",
    "C_sqname_list_questions, C_sqname_n_of_questions = count_number_of_questions_sqname(country_questionnaire_file)\n",
    "C_qname_list_questions, C_qname_n_of_questions = count_number_of_questions_qname(country_questionnaire_file)\n",
    "\n",
    "message1 = \"QName Field - Number of questions in the Template Questionnaire: %s\" % T_qname_n_of_questions\n",
    "message2 = \"QName Field - Number of questions in the Country Questionnaire: %s\\n\" % C_qname_n_of_questions\n",
    "message3 = \"SuggestedQName Field - Number of questions in the Template Questionnaire: %s\" % T_sqname_n_of_questions\n",
    "message4 = \"SuggestedQName Field - Number of questions in the Country Questionnaire: %s\" % C_sqname_n_of_questions\n",
    "execution_messages += \"\\n%s\\n%s\\n%s\\n%s\" % (message1, message2, message3, message4)\n",
    "print(message1)\n",
    "print(message2)\n",
    "print(message3)\n",
    "print(message4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "linear-forty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETECTING DIFFERENCES IN FIELD: Suggested QName\n",
      "\n",
      "Questions in country questionnaire and not in template questionnaire: ['hh_wealth_water']\n",
      "Questions in template questionnaire and not in country questionnaire: ['hh_wealth_water\\n\\n1)hh_wealth_water_pvttap\\n2)hh_wealth_water_publictap\\n3)hh_wealth_water_protectwell\\n4)hh_wealth_water_bottle\\n5)hh_wealth_water_othersafe\\n6)hh_wealth_water_river\\n7)hh_wealth_water_unprotectwell\\n8)hh_wealth_water_spring\\n9)hh_wealth_water_canalsurface\\n10)hh_wealth_water_otherunsafe\\n11)hh_wealth_water_dk\\n12)hh_wealth_water_ref']\n"
     ]
    }
   ],
   "source": [
    "print (\"DETECTING DIFFERENCES IN FIELD: Suggested QName\")\n",
    "\n",
    "message5 = \"\\nQuestions in country questionnaire and not in template questionnaire: %s\" % list(set(C_sqname_list_questions) - set(T_sqname_list_questions))\n",
    "message6 = \"Questions in template questionnaire and not in country questionnaire: %s\" % list(set(T_sqname_list_questions) - set(C_sqname_list_questions))\n",
    "execution_messages += \"\\n%s\\n%s\" % (message5, message6)\n",
    "print (message5)\n",
    "print (message6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "chicken-marking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETECTING DIFFERENCES IN FIELD: Q Name\n",
      "\n",
      "Questions in country questionnaire and not in template questionnaire: ['hh_head', 'crp_landdoc']\n",
      "Questions in template questionnaire and not in country questionnaire: []\n"
     ]
    }
   ],
   "source": [
    "print (\"DETECTING DIFFERENCES IN FIELD: Q Name\")\n",
    "\n",
    "message7 = \"\\nQuestions in country questionnaire and not in template questionnaire: %s\" % list(set(C_qname_list_questions) - set(T_qname_list_questions))\n",
    "message8 = \"Questions in template questionnaire and not in country questionnaire: %s\" % list(set(T_qname_list_questions) - set(C_qname_list_questions))\n",
    "execution_messages += \"\\n%s\\n%s\" % (message7, message8)\n",
    "print (message7)\n",
    "print (message8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "virtual-actress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECKING THAT ALL MANDATORY QUESTIONS ARE INCLUDED IN THE COUNTRY QUESTIONNAIRE\n",
      "\n",
      "Found 63 mandatory questions in the template questionnaire\n",
      "Yes, country questionnaire contains all mandatory questions\n"
     ]
    }
   ],
   "source": [
    "print (\"CHECKING THAT ALL MANDATORY QUESTIONS ARE INCLUDED IN THE COUNTRY QUESTIONNAIRE\")\n",
    "\n",
    "quest_df = pd.read_excel(open(questionnaire_file, 'rb'), sheet_name='survey',skiprows=2)\n",
    "#print(list(quest_df.columns.values))\n",
    "quest_df.rename(columns={'Unnamed: 19': 'Mandatory'}, inplace=True)\n",
    "list_mandatory_questions = quest_df.loc[quest_df[\"Mandatory\"] == \"yes\"][\"Q Name\"].values.tolist() \n",
    "message9 = \"\\nFound %s mandatory questions in the template questionnaire\" % len(list_mandatory_questions)\n",
    "print(message9)\n",
    "\n",
    "result =  all(elem in C_qname_list_questions  for elem in list_mandatory_questions)\n",
    "if result:\n",
    "    message10 = \"Yes, country questionnaire contains all mandatory questions\"   \n",
    "else:\n",
    "    message10 = \"No, country questionnaire does not contains all mandatory questions. Missing question: %s \" % list(set(list_mandatory_questions ) - set(C_qname_list_questions))\n",
    "print(message10)\n",
    "    \n",
    "execution_messages += \"\\n%s\\n%s\" % (message9, message10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "republican-panel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECKING THAT RULES ON CS QUESTIONS ARE RESPECTED\n",
      "\n",
      "\n",
      "17 CS questions found in the country questionnaire\n",
      "There should be 3 questions for each group.\n",
      "Number of STRESS questions: 6\n",
      "Number of CRISIS questions: 6\n",
      "Number of EMERGENCY questions: 5\n"
     ]
    }
   ],
   "source": [
    "print (\"CHECKING THAT RULES ON CS QUESTIONS ARE RESPECTED\\n\")\n",
    "\n",
    "cs_questions_in_country = [i for i in C_qname_list_questions if i.startswith('cs')]\n",
    "if len(cs_questions_in_country) > 0:\n",
    "    cs_stress_questions_in_country = [i for i in C_qname_list_questions if i.startswith('cs_stress')]\n",
    "    cs_emergency_questions_in_country = [i for i in C_qname_list_questions if i.startswith('cs_emergency')]\n",
    "    cs_crisis_questions_in_country = [i for i in C_qname_list_questions if i.startswith('cs_crisis')]\n",
    "    message11 = \"\\n%s CS questions found in the country questionnaire\\n\" % len(cs_questions_in_country) + \"There should be 3 questions for each group.\\nNumber of STRESS questions: %s\" % len(cs_stress_questions_in_country) + \"\\nNumber of CRISIS questions: %s\\n\" % len(cs_crisis_questions_in_country) + \"Number of EMERGENCY questions: %s\" % len(cs_emergency_questions_in_country)\n",
    "\n",
    "else:\n",
    "    message11 = \"\\nNo CS questions in the country questionnaire\"\n",
    "\n",
    "print(message11)\n",
    "\n",
    "execution_messages += \"\\n%s\" % (message11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "tracked-template",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECKING THAT RULES ON HDDS QUESTIONS ARE RESPECTED\n",
      "\n",
      "There should be either 0 or 2 HDDS questions\n",
      "Number of HDDS questions: 2  - ['hdds', 'hdds_confirmation']\n"
     ]
    }
   ],
   "source": [
    "print (\"CHECKING THAT RULES ON HDDS QUESTIONS ARE RESPECTED\")\n",
    "\n",
    "hdds_questions_in_country = [i for i in C_qname_list_questions if i.startswith('hdds')]\n",
    "message12 = \"\\nThere should be either 0 or 2 HDDS questions\"\n",
    "\n",
    "if len(hdds_questions_in_country) > 0:\n",
    "    message12 += \"\\nNumber of HDDS questions: %s  - %s\" % (len(hdds_questions_in_country), hdds_questions_in_country)\n",
    "else:\n",
    "    message12 += \"No HDDS questions in the country questionnaire\"\n",
    "    execution_messages += \"\\n%s\" % (message12)\n",
    "\n",
    "print(message12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "designed-coffee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARING DOMAINS AND DERIVED FIELDS\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "Domains have been changed for question: hh_education\n",
      "   code                                 label\n",
      "4     5  Islamic or other religious education\n",
      "4     5                     Islamic education\n",
      "\n",
      "-------\n",
      "\n",
      "Domains have been changed for question: hh_wealth_toilet\n",
      "   code                              label\n",
      "0     1  Flush latrine (toilet with water)\n",
      "5     6                         Don't know\n",
      "6     7                            Refused\n",
      "0     1    Flush latrine/toilet with water\n",
      "\n",
      "-------\n",
      "\n",
      "Domains have been changed for question: hh_wealth_light\n",
      "   code       label\n",
      "5     6  Don'tk now\n",
      "6     7     Refused\n",
      "\n",
      "-------\n",
      "\n",
      "Domains have been changed for question: income_sec\n",
      "   code                                        label\n",
      "0     1  Farmer, production and sale of cereal crops\n",
      "0     1  Farmer, production and sale of staple crops\n",
      "\n",
      "-------\n",
      "\n",
      "Domains have been changed for question: income_third\n",
      "    code                                        label\n",
      "0      1  Farmer, production and sale of cereal crops\n",
      "18    19    No second most important source of income\n",
      "0      1  Farmer, production and sale of staple crops\n",
      "18    19     No third most important source of income\n",
      "\n",
      "-------\n",
      "\n",
      "Derived fields analysis: \n",
      "Derived field only in template: ['hh_wealth_water_spring', 'hh_wealth_water_ref', 'hh_wealth_water_canalsurface', 'hh_wealth_water_bottle', 'hh_wealth_water_unprotectwell', 'hh_wealth_water_publictap', 'hh_wealth_water_protectwell', 'hh_wealth_water_othersafe', 'hh_wealth_water_otherunsafe', 'hh_wealth_water_pvttap', 'hh_wealth_water_dk', 'hh_wealth_water_river']\n",
      "Derived field only in country: []\n"
     ]
    }
   ],
   "source": [
    "print(\"COMPARING DOMAINS AND DERIVED FIELDS\")\n",
    "all_domains_respected = True\n",
    "domain_messages = ''\n",
    "dict_with_dfs_template = pd.read_excel(coded_values_file, sheet_name=None)\n",
    "dict_with_dfs_country = pd.read_excel(country_coded_values_file, sheet_name=None)\n",
    "for template_question, template_domains in dict_with_dfs_template.items():\n",
    "    if template_question in dict_with_dfs_country:\n",
    "        #print(template_question)\n",
    "        if template_question == 'derived_fields':\n",
    "            domain_messages += \"\\n\\n-------\\n\"\n",
    "            domain_messages += \"\\nDerived fields analysis: \"\n",
    "            derived_fields_country = list(dict_with_dfs_country[template_question][0].tolist())\n",
    "            derived_fields_template = list(template_domains[0].tolist())\n",
    "            derived_fields_only_country = list(set(derived_fields_country ) - set(derived_fields_template))\n",
    "            derived_fields_only_template = list(set(derived_fields_template ) - set(derived_fields_country))\n",
    "            if len(derived_fields_only_country) == 0 and len(derived_fields_only_template) == 0:\n",
    "                domain_messages += \"\\nDerived fields have been respected\"\n",
    "            else:\n",
    "                domain_messages += \"\\nDerived field only in template: %s\" % derived_fields_only_template\n",
    "                domain_messages += \"\\nDerived field only in country: %s\" % derived_fields_only_country\n",
    "        elif template_question == 'crp_main':\n",
    "            pass ##crp domains are going to be edited by the script - no need to check the now#\n",
    "        else:\n",
    "            df_diff = pd.concat([template_domains,dict_with_dfs_country[template_question]]).drop_duplicates(keep=False)\n",
    "            del df_diff['Unnamed: 0']\n",
    "            if not df_diff.empty:\n",
    "                domain_messages += \"\\n\\n-------\\n\"\n",
    "                all_domains_respected = False\n",
    "                domain_messages += \"\\nDomains have been changed for question: %s\" % template_question\n",
    "                #print(\"First row is the template domain, second row is the country domain\")\n",
    "                with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "                    #print(df_diff)\n",
    "                    domain_messages += \"\\n%s\" % df_diff.to_string()\n",
    "            \n",
    "            \n",
    "if all_domains_respected == True:\n",
    "    domain_messages += \"\\nAll domains have been respected\"\n",
    "\n",
    "print (domain_messages)\n",
    "execution_messages += \"\\n%s\" % (domain_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "nutritional-terror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE OUTPUT VALIDATED QUESTIONNAIRE FILE\n"
     ]
    }
   ],
   "source": [
    "print (\"CREATE OUTPUT VALIDATED QUESTIONNAIRE FILE\")\n",
    "iso3 = \"MLI\" #####to be removed\n",
    "country_questionnaire_edited_file = os.path.join(temp_path, \"validated_questionnaire_geopoll_%s_%s.xlsx\" % (iso3, now)) \n",
    "copyfile(country_questionnaire_file, country_questionnaire_edited_file)\n",
    "execution_messages += \"\\n\\nOutput validated qcountry questionnaire: %s\" % (country_questionnaire_edited_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "serious-cotton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT ADMIN SHEET WITH UPDATED BOUNDARIES\n"
     ]
    }
   ],
   "source": [
    "print(\"INSERT ADMIN SHEET WITH UPDATED BOUNDARIES\")\n",
    "\n",
    "sdf = insert_sheet_with_adm2_reference(country_questionnaire_edited_file,iso3)\n",
    "sdf.head()\n",
    "execution_messages += \"\\n\\nCreated Admin Info sheet with updated boundaries: %s\" % (country_questionnaire_edited_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "widespread-designation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDITING THE SURVEY BY SORTING THE CROP LIST VALUES ACCORDING TO PRIORITISE\n",
      "\n",
      "Number of most common crops selected in the Crop list sheet: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"EDITING THE SURVEY BY SORTING THE CROP LIST VALUES ACCORDING TO PRIORITISE\")\n",
    "n_of_choices = sort_crop_list_by_selection(country_questionnaire_edited_file)\n",
    "message13 = \"\\nNumber of most common crops selected in the Crop list sheet: %s\" % n_of_choices\n",
    "print(message13)\n",
    "execution_messages += \"\\n\\nSurvey edited by sorting the crop list according to the prioritise\" + message13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "acoustic-western",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDITING THE SURVEY BY REPLACING VALUES ACCORDING ADDITIONAL INFO SHEET\n"
     ]
    }
   ],
   "source": [
    "print(\"EDITING THE SURVEY BY REPLACING VALUES ACCORDING ADDITIONAL INFO SHEET\")\n",
    "find_and_replace_strings_in_df(country_questionnaire_edited_file)\n",
    "execution_messages += \"\\n\\nSurvey edited by replacing values according the Additional Information sheet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "chemical-headset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create output file with execution messages\n"
     ]
    }
   ],
   "source": [
    "print(\"Create output file with execution messages\")\n",
    "text_file = os.path.join(temp_path, \"questionnaire_validation_report_%s_%s.txt\" % (iso3, now)) \n",
    "file = open(text_file, \"w\") \n",
    "file.write(execution_messages) \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "imposed-pearl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  0:00:07.812931\n"
     ]
    }
   ],
   "source": [
    "print(\"Execution time: \", datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-macro",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
